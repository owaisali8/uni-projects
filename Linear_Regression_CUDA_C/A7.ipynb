{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "92jHbMMWnz-m"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment-7 ðŸ“š\n",
        "## CSE-467 - Parallel and Distributed Computing ðŸ’»\n",
        "### Syed Owais Ali - 23053\n",
        "\n",
        "Design EREW-PRAM model for linear regression for 16 elements and then implement it in CUDA-C or CUDA-Python for N elements. Compare the sequential implementation with parallel implementation. Fill execution time in the following table for the given values of N. You can implement the solution with local shared variable among threads within a block and with global variable shared among all blocks. \n",
        "\n",
        "---\n",
        "  \n",
        "\n",
        "|N (Array length) | Sequential | Shared variable Partial Sums (GPU)| Global variable One Final Sum (GPU) |\n",
        "|--|--| -- | -- |\n",
        "|  1 x 10<sup>6</sup> |  | | |\n",
        "|  10 x 10<sup>6</sup>|  | | |\n",
        "|  20 x 10<sup>6</sup>|  | | |\n",
        "|  35 x 10<sup>6</sup>|  | | |\n",
        "|  40 x 10<sup>6</sup>|  | | |\n",
        "|  50 x 10<sup>6</sup>|  | | |\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3aAuloFd-Aeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "SpHEreYn6hF1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tB55RKtO9tnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87441c79-49a0-4f93-e437-69483cf3c8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 15 20:45:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsb_release -a"
      ],
      "metadata": {
        "id": "GHkgMsQR_Apg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5095dab-a847-4023-d780-89cc45ea037c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 20.04.5 LTS\n",
            "Release:\t20.04\n",
            "Codename:\tfocal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "ahPYs-hj_CiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b401bdb7-5f45-4f99-c30b-13ceff480488"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "DDu8x09U_Dxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fedafc-9e91-4849-8896-739b00bef229"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-so3iq5r1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-so3iq5r1\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=6dfacd6feb0ae3b3236bacc98df11e538bfd19392e14ca6e1593528ac6682eca\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ebw3p8a/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "vyZ6BZ3B_FYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0ce71d-6cca-438e-815c-449632e1b70a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential"
      ],
      "metadata": {
        "id": "92jHbMMWnz-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <math.h>\n",
        "#define N 1000000\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // Number of bytes to allocate for N doubles\n",
        "    size_t bytes = N*sizeof(int);\n",
        "\n",
        "    // Allocate memory for arrays A, B on host\n",
        "    int *X = (int*)malloc(bytes);\n",
        "    int *Y = (int*)malloc(bytes);\n",
        "    long double sum_y = 0.0;\n",
        "    long double sum_x = 0.0;\n",
        "    long double sum_x_squared = 0.0;\n",
        "    long double sum_xy = 0.0;\n",
        "    long double A = 0.0;\n",
        "    long double B = 0.0;\n",
        "  \n",
        "    struct timeval start, end;\n",
        "\n",
        "  \n",
        "    for (int i = 0; i < N; i++) {\n",
        "        X[i] = rand() % 100;\n",
        "        Y[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "\n",
        "    \n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sum_y += Y[i];\n",
        "        sum_x += X[i];\n",
        "        sum_x_squared += pow(X[i], 2);\n",
        "        sum_xy += (X[i] * Y[i]);\n",
        "    }\n",
        " \n",
        "    // printf(\"sum_y %d\\n\", sum_y);\n",
        "    // printf(\"sum_x %d\\n\", sum_x);\n",
        "    // printf(\"sum_x_squared %llu\\n\", sum_x_squared);\n",
        "    // printf(\"sum_xy %llu\\n\", sum_xy);\n",
        " \n",
        "    A = ((sum_y * sum_x_squared) - (sum_x * sum_xy))/((N * sum_x_squared) - pow(sum_x, 2));\n",
        "    B = ((N * sum_xy) - (sum_x * sum_y))/((N * sum_x_squared) - (sum_x_squared));\n",
        " \n",
        "    gettimeofday(&end, NULL);\n",
        "    long seconds = (end.tv_sec - start.tv_sec);\n",
        "    long micros = ((seconds * 1000000) + end.tv_usec) - (start.tv_usec);\n",
        " \n",
        "    printf(\"y= a + bx\\n\");\n",
        "    printf(\"Sequential Linear Regression: A = %Lf and B = %Lf\\n\", A, B);\n",
        "    printf(\"The elapsed time by CPU is %ds and %dus \\n\", seconds, micros); \n",
        "\n",
        "    free(X);\n",
        "    free(Y);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "N8Mb_lPt_HN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6a8daf-d859-44b4-85a0-83984ec613b2"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y= a + bx\n",
            "Sequential Linear Regression: A = 49.509458 and B = -0.000154\n",
            "The elapsed time by CPU is 0s and 35001us \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shared variable Partial Sums (GPU)"
      ],
      "metadata": {
        "id": "T7zzaumdsusm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <math.h>\n",
        "#define N 50000000\n",
        "\n",
        "\n",
        "__global__ void linear_regression_shared(double *A, double *B, int *X, int *Y, int *sum_y, int *sum_x, int *sum_x_squared, int *sum_xy)\n",
        "{\n",
        "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    int tid = threadIdx.x;\n",
        "    int blockId = blockIdx.x;\n",
        "    __shared__ int temp_y[256];\n",
        "    __shared__ int temp_x[256];\n",
        "    __shared__ int temp_x_sqr[256];\n",
        "    __shared__ int temp_xy[256];\n",
        " \n",
        "    if(id < N) {\n",
        "        temp_y[tid] =  Y[id];\n",
        "        temp_x[tid] =  X[id];\n",
        "        temp_x_sqr[tid] =  X[id] * X[id];\n",
        "        temp_xy[tid] =  X[id] * Y[id];\n",
        "    }\n",
        " \n",
        "    __syncthreads();\n",
        " \n",
        "    if (tid == 0) {\n",
        "        for(int i =0; i<256; i++){\n",
        "            atomicAdd(sum_y, temp_y[i]);\n",
        "            atomicAdd(sum_x, temp_x[i]);\n",
        "            atomicAdd(sum_x_squared, temp_x_sqr[i]);\n",
        "            atomicAdd(sum_xy, temp_xy[i]);\n",
        "        }\n",
        "    }\n",
        " \n",
        "    if (id == 0) {\n",
        "        *A = ((double) (*sum_y * *sum_x_squared) - (*sum_x * *sum_xy))/((N * *sum_x_squared) - pow(*sum_x, 2));\n",
        "        *B = ((double) (N * *sum_xy) - (*sum_x * *sum_y))/((N * *sum_x_squared) - (*sum_x_squared));\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // Number of bytes to allocate for N doubles\n",
        "    size_t bytes = N*sizeof(int);\n",
        "\n",
        "    // Allocate memory for arrays A, B on host\n",
        "    int *X = (int*)malloc(bytes);\n",
        "    int *Y = (int*)malloc(bytes);\n",
        "    long double sum_y = 0.0;\n",
        "    long double sum_x = 0.0;\n",
        "    long double sum_x_squared = 0.0;\n",
        "    long double sum_xy = 0.0;\n",
        "    long double A = 0.0;\n",
        "    long double B = 0.0;\n",
        "  \n",
        "    struct timeval start, end;\n",
        "\n",
        "  \n",
        "    for (int i = 0; i < N; i++) {\n",
        "        X[i] = rand() % 10;\n",
        "        Y[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "\n",
        "    \n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sum_y += Y[i];\n",
        "        sum_x += X[i];\n",
        "        sum_x_squared += pow(X[i], 2);\n",
        "        sum_xy += (X[i] * Y[i]);\n",
        "    }\n",
        " \n",
        "    // printf(\"sum_y %d\\n\", sum_y);\n",
        "    // printf(\"sum_x %d\\n\", sum_x);\n",
        "    // printf(\"sum_x_squared %llu\\n\", sum_x_squared);\n",
        "    // printf(\"sum_xy %llu\\n\", sum_xy);\n",
        " \n",
        "    A = ((sum_y * sum_x_squared) - (sum_x * sum_xy))/((N * sum_x_squared) - pow(sum_x, 2));\n",
        "    B = ((N * sum_xy) - (sum_x * sum_y))/((N * sum_x_squared) - (sum_x_squared));\n",
        " \n",
        "    gettimeofday(&end, NULL);\n",
        "    long seconds = (end.tv_sec - start.tv_sec);\n",
        "    long micros = ((seconds * 1000000) + end.tv_usec) - (start.tv_usec);\n",
        " \n",
        "    printf(\"y= a + bx\\n\");\n",
        "    printf(\"Sequential Linear Regression: A = %Lf and B = %Lf\\n\", A, B);\n",
        "    printf(\"The elapsed time by CPU is %ds and %dus \\n\", seconds, micros); \n",
        " \n",
        "    int *d_X, *d_Y;\n",
        "    double *d_A, *d_B;\n",
        "    int *d_sum_y, *d_sum_x, *d_sum_x_squared, *d_sum_xy;\n",
        "    cudaMalloc(&d_X, bytes);\n",
        "    cudaMalloc(&d_Y, bytes);\n",
        "    cudaMalloc(&d_A, sizeof(double));\n",
        "    cudaMalloc(&d_B, sizeof(double));\n",
        "    cudaMalloc(&d_sum_y, sizeof(int));\n",
        "    cudaMalloc(&d_sum_x, sizeof(int));\n",
        "    cudaMalloc(&d_sum_x_squared, sizeof(int)); \n",
        "    cudaMalloc(&d_sum_xy, sizeof(int)); \n",
        " \n",
        "    cudaMemcpy(d_X, X, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_Y, Y, bytes, cudaMemcpyHostToDevice);\n",
        " \n",
        "    int thr_per_blk = 256;\n",
        "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
        "\n",
        "    // Launch kernel\n",
        "    gettimeofday(&start, NULL);\n",
        "    linear_regression_shared<<< blk_in_grid, thr_per_blk >>>(d_A, d_B, d_X, d_Y, d_sum_y, d_sum_x, d_sum_x_squared, d_sum_xy);\n",
        " \n",
        "    cudaDeviceSynchronize();\n",
        " \n",
        "    gettimeofday(&end, NULL);\n",
        "    seconds = (end.tv_sec - start.tv_sec);\n",
        "    micros = ((seconds * 1000000) + end.tv_usec) - (start.tv_usec);\n",
        "\n",
        "    double *A_from_GPU = (double*)malloc(sizeof(double));\n",
        "    double *B_from_GPU = (double*)malloc(sizeof(double));\n",
        " \n",
        "    // Copy data from device array d_C to host array C\n",
        "    cudaMemcpy(A_from_GPU, d_A, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(B_from_GPU, d_B, sizeof(double), cudaMemcpyDeviceToHost);\n",
        " \n",
        "    printf(\"y= a + bx\\n\");\n",
        "    printf(\"Shared Memory Linear Regression: A = %f and B = %f\\n\", *A_from_GPU, *B_from_GPU);\n",
        "    printf(\"The elapsed time by GPU is %ds and %dus \\n\", seconds, micros); \n",
        "\n",
        "\n",
        "    free(X);\n",
        "    free(Y);\n",
        "    free(A_from_GPU);\n",
        "    free(B_from_GPU);\n",
        " \n",
        "    cudaFree(d_X);\n",
        "    cudaFree(d_Y);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_sum_y);\n",
        "    cudaFree(d_sum_x);\n",
        "    cudaFree(d_sum_x_squared);\n",
        "    cudaFree(d_sum_xy);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHQMT3s2sM0R",
        "outputId": "4995ae54-720a-4f23-f7cf-4b5b054beef3"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y= a + bx\n",
            "Sequential Linear Regression: A = 4.499719 and B = 0.000016\n",
            "The elapsed time by CPU is 2s and 1842252us \n",
            "y= a + bx\n",
            "Shared Memory Linear Regression: A = -0.021426 and B = -10.501242\n",
            "The elapsed time by GPU is 0s and 140269us \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global variable One Final Sum (GPU)\n"
      ],
      "metadata": {
        "id": "groeSSYa4pYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <math.h>\n",
        "#define N 50000000\n",
        "\n",
        "\n",
        "__global__ void linear_regression_global(double *A, double *B, int *X, int *Y, int *sum_y, int *sum_x, int *sum_x_squared, int *sum_xy)\n",
        "{\n",
        "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    int blockId = blockIdx.x;\n",
        "    if(id < N) {\n",
        "        atomicAdd(sum_y, Y[id]);\n",
        "        atomicAdd(sum_x, X[id]);\n",
        "        atomicAdd(sum_x_squared, X[id]*X[id]);\n",
        "        atomicAdd(sum_xy, X[id] * Y[id]);\n",
        "    }\n",
        " \n",
        "    __syncthreads();\n",
        " \n",
        "    if (id == 0) {\n",
        "        *A = ((double) (*sum_y * *sum_x_squared) - (*sum_x * *sum_xy))/((N * *sum_x_squared) - pow(*sum_x, 2));\n",
        "        *B = ((double) (N * *sum_xy) - (*sum_x * *sum_y))/((N * *sum_x_squared) - (*sum_x_squared));\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // Number of bytes to allocate for N doubles\n",
        "    size_t bytes = N*sizeof(int);\n",
        "\n",
        "    // Allocate memory for arrays A, B on host\n",
        "    int *X = (int*)malloc(bytes);\n",
        "    int *Y = (int*)malloc(bytes);\n",
        "    long double sum_y = 0.0;\n",
        "    long double sum_x = 0.0;\n",
        "    long double sum_x_squared = 0.0;\n",
        "    long double sum_xy = 0.0;\n",
        "    long double A = 0.0;\n",
        "    long double B = 0.0;\n",
        "  \n",
        "    struct timeval start, end;\n",
        "\n",
        "  \n",
        "    for (int i = 0; i < N; i++) {\n",
        "        X[i] = rand() % 10;\n",
        "        Y[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    gettimeofday(&start, NULL);\n",
        "\n",
        "    \n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sum_y += Y[i];\n",
        "        sum_x += X[i];\n",
        "        sum_x_squared += pow(X[i], 2);\n",
        "        sum_xy += (X[i] * Y[i]);\n",
        "    }\n",
        " \n",
        "    // printf(\"sum_y %d\\n\", sum_y);\n",
        "    // printf(\"sum_x %d\\n\", sum_x);\n",
        "    // printf(\"sum_x_squared %llu\\n\", sum_x_squared);\n",
        "    // printf(\"sum_xy %llu\\n\", sum_xy);\n",
        " \n",
        "    A = ((sum_y * sum_x_squared) - (sum_x * sum_xy))/((N * sum_x_squared) - pow(sum_x, 2));\n",
        "    B = ((N * sum_xy) - (sum_x * sum_y))/((N * sum_x_squared) - (sum_x_squared));\n",
        " \n",
        "    gettimeofday(&end, NULL);\n",
        "    long seconds = (end.tv_sec - start.tv_sec);\n",
        "    long micros = ((seconds * 1000000) + end.tv_usec) - (start.tv_usec);\n",
        " \n",
        "    printf(\"y= a + bx\\n\");\n",
        "    printf(\"Sequential Linear Regression: A = %Lf and B = %Lf\\n\", A, B);\n",
        "    printf(\"The elapsed time by CPU is %ds and %dus \\n\", seconds, micros); \n",
        " \n",
        "    int *d_X, *d_Y;\n",
        "    double *d_A, *d_B;\n",
        "    int *d_sum_y, *d_sum_x, *d_sum_x_squared, *d_sum_xy;\n",
        "    cudaMalloc(&d_X, bytes);\n",
        "    cudaMalloc(&d_Y, bytes);\n",
        "    cudaMalloc(&d_A, sizeof(double));\n",
        "    cudaMalloc(&d_B, sizeof(double));\n",
        "    cudaMalloc(&d_sum_y, sizeof(int));\n",
        "    cudaMalloc(&d_sum_x, sizeof(int));\n",
        "    cudaMalloc(&d_sum_x_squared, sizeof(int)); \n",
        "    cudaMalloc(&d_sum_xy, sizeof(int)); \n",
        " \n",
        "    cudaMemcpy(d_X, X, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_Y, Y, bytes, cudaMemcpyHostToDevice);\n",
        " \n",
        "    int thr_per_blk = 256;\n",
        "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
        "\n",
        "    // Launch kernel\n",
        "    gettimeofday(&start, NULL);\n",
        "    linear_regression_global<<< blk_in_grid, thr_per_blk >>>(d_A, d_B, d_X, d_Y, d_sum_y, d_sum_x, d_sum_x_squared, d_sum_xy);\n",
        " \n",
        "    cudaDeviceSynchronize();\n",
        " \n",
        "    gettimeofday(&end, NULL);\n",
        "    seconds = (end.tv_sec - start.tv_sec);\n",
        "    micros = ((seconds * 1000000) + end.tv_usec) - (start.tv_usec);\n",
        "\n",
        "    double *A_from_GPU = (double*)malloc(sizeof(double));\n",
        "    double *B_from_GPU = (double*)malloc(sizeof(double));\n",
        " \n",
        "    // Copy data from device array d_C to host array C\n",
        "    cudaMemcpy(A_from_GPU, d_A, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(B_from_GPU, d_B, sizeof(double), cudaMemcpyDeviceToHost);\n",
        " \n",
        "    printf(\"y= a + bx\\n\");\n",
        "    printf(\"Global Linear Regression: A = %f and B = %f\\n\", *A_from_GPU, *B_from_GPU);\n",
        "    printf(\"The elapsed time by GPU is %ds and %dus \\n\", seconds, micros); \n",
        "\n",
        "\n",
        "    free(X);\n",
        "    free(Y);\n",
        "    free(A_from_GPU);\n",
        "    free(B_from_GPU);\n",
        " \n",
        "    cudaFree(d_X);\n",
        "    cudaFree(d_Y);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_sum_y);\n",
        "    cudaFree(d_sum_x);\n",
        "    cudaFree(d_sum_x_squared);\n",
        "    cudaFree(d_sum_xy);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_58uNnzl4Oax",
        "outputId": "dd72d000-3189-4ebf-8dcf-053185beab57"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y= a + bx\n",
            "Sequential Linear Regression: A = 4.499719 and B = 0.000016\n",
            "The elapsed time by CPU is 2s and 1995478us \n",
            "y= a + bx\n",
            "Global Linear Regression: A = 0.073646 and B = -0.778793\n",
            "The elapsed time by GPU is 0s and 5662us \n",
            "\n"
          ]
        }
      ]
    }
  ]
}